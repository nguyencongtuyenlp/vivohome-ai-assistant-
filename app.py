"""
VIVOHOME AI - Gradio App with Direct Tools
Compatible v·ªõi Gradio 4.x v√† 5.x
"""

import gradio as gr
from tools import lookup_csv, search_products, extract_model, describe_image
from logger import app_logger
from query_parser import parse_query
from database import search_with_intent

app_logger.info("üöÄ VIVOHOME AI Starting...")

def chat_with_agent(message, history):
    """X·ª≠ l√Ω tin nh·∫Øn - g·ªçi tools tr·ª±c ti·∫øp"""
    # Parse message
    user_text = message.get("text", "") if isinstance(message, dict) else str(message)
    user_files = message.get("files", []) if isinstance(message, dict) else []
    
    # Log query
    app_logger.info(f"üì• User query: {user_text[:100]}")
    
    image_path = None
    if user_files:
        image_path = user_files[0] if isinstance(user_files[0], str) else user_files[0].name
        app_logger.info(f"üì∑ Image uploaded: {image_path}")
    
    try:
        # === TR∆Ø·ªúNG H·ª¢P 1: C√ì ·∫¢NH ===
        if image_path:
            # B∆∞·ªõc 1: Tr√≠ch xu·∫•t Model
            model_result = extract_model(image_path)
            
            if model_result.get("found"):
                model_code = model_result["model"]
                app_logger.info(f"‚úÖ Extracted model: {model_code}")
                
                # B∆∞·ªõc 2: Tra c·ª©u Database
                product = lookup_csv(model_code)
                
                if product.get("found"):
                    app_logger.info(f"‚úÖ Product found: {product['ten_san_pham']}")
                    return f"""üì¶ **Th√¥ng tin s·∫£n ph·∫©m t·ª´ ·∫£nh:**
- T√™n: {product['ten_san_pham']}
- Model: {product['model']}
- Gi√°: **{product['gia']:,} VND**
- Nh√≥m: {product['nhom_hang']}

_Tr√≠ch xu·∫•t t·ª´ ·∫£nh: Model {model_code}_"""
                else:
                    app_logger.warning(f"‚ö†Ô∏è Model not in DB: {model_code}")
                    return f"ƒê√£ tr√≠ch xu·∫•t Model: {model_code}, nh∆∞ng kh√¥ng t√¨m th·∫•y trong h·ªá th·ªëng VIVOHOME."
            else:
                app_logger.warning("‚ö†Ô∏è Cannot extract model from image")
                # Fallback: M√¥ t·∫£ ·∫£nh
                desc_result = describe_image(image_path)
                if desc_result.get("success"):
                    return f"üì∑ {desc_result['description']}\n\n_Kh√¥ng t√¨m th·∫•y m√£ Model tr√™n ·∫£nh ƒë·ªÉ tra gi√°._"
                else:
                    return "Kh√¥ng th·ªÉ ƒë·ªçc ƒë∆∞·ª£c th√¥ng tin t·ª´ ·∫£nh."
        
        # === TR∆Ø·ªúNG H·ª¢P 2: CH·ªà TEXT - FULL RAG SEARCH ===
        else:
            # Try RAG engine first
            try:
                from rag_engine import rag_engine
                
                # Full RAG search with semantic + web fallback
                app_logger.info(f"üß† RAG Search: {user_text}")
                response = rag_engine.process(user_text)
                return response
                
            except ImportError as e:
                # Fallback to basic search if RAG not available
                app_logger.warning(f"‚ö†Ô∏è RAG Engine not available: {e}")
                
                intent = parse_query(user_text)
                search_result = search_with_intent(user_text, intent, max_results=3)
                
                if search_result.get("found"):
                    products = search_result["products"]
                    lines = ["üì¶ **S·∫£n ph·∫©m t√¨m ƒë∆∞·ª£c:**"]
                    for p in products:
                        lines.append(f"- {p['ten']} ({p['model']}): **{p['gia']:,} VND**")
                    return "\n".join(lines)
                else:
                    return "Xin l·ªói, kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m."
    
    except Exception as e:
        app_logger.error(f"‚ùå Error: {str(e)}", exc_info=True)
        return f"‚ùå L·ªói: {str(e)}\n\nƒê·∫£m b·∫£o vLLM Server ƒëang ch·∫°y!"

# === GRADIO UI WITH CUSTOM THEME ===

# Custom CSS for modern look
custom_css = """
#chatbot {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    border-radius: 15px;
    box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
}

.message-wrap {
    background: rgba(255, 255, 255, 0.95) !important;
    border-radius: 12px !important;
    padding: 12px !important;
    margin: 8px 0 !important;
    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05) !important;
}

.bot .message-wrap {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
    color: white !important;
}

.user .message-wrap {
    background: #f8f9fa !important;
}

#component-0 {
    background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
}

.contain {
    max-width: 1200px !important;
    margin: auto !important;
}

h1 {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    font-weight: 800 !important;
    font-size: 2.5em !important;
    text-align: center !important;
    margin-bottom: 0.5em !important;
}

.description {
    text-align: center;
    font-size: 1.1em;
    color: #555;
    margin-bottom: 2em;
}

.example-container {
    background: white;
    border-radius: 12px;
    padding: 15px;
    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.08);
    margin: 10px 0;
}

footer {
    text-align: center;
    margin-top: 2em;
    color: #888;
    font-size: 0.9em;
}
"""

# Create Gradio interface with custom theme
with gr.Blocks(
    theme=gr.themes.Soft(
        primary_hue="purple",
        secondary_hue="blue",
        neutral_hue="slate",
        font=gr.themes.GoogleFont("Inter"),
    ),
    css=custom_css,
    title="VIVOHOME AI - Smart Shopping Assistant"
) as demo:
    
    # Header
    gr.Markdown(
        """
        # üè¢ VIVOHOME AI Assistant
        ### Tr·ª£ l√Ω mua s·∫Øm th√¥ng minh v·ªõi Vision AI
        """
    )
    
    # Description with icons
    gr.Markdown(
        """
        <div class="description">
        <p>üß† <b>Intent Detection</b> ‚Ä¢ üîç <b>Smart Search</b> ‚Ä¢ üì∑ <b>Vision-RAG</b></p>
        <p style="color: #888; font-size: 0.95em;">H·ªèi v·ªÅ gi√° s·∫£n ph·∫©m b·∫±ng text ho·∫∑c upload ·∫£nh tem nh√£n</p>
        </div>
        """,
        elem_classes="description"
    )
    
    # Main chat interface
    chatbot = gr.Chatbot(
        label="üí¨ Chat",
        height=500,
        show_label=False,
        avatar_images=(
            None,  # User avatar
            "https://raw.githubusercontent.com/gradio-app/gradio/main/guides/assets/logo.png"  # Bot avatar
        ),
        elem_id="chatbot"
    )
    
    # Input area
    with gr.Row():
        with gr.Column(scale=4):
            msg = gr.MultimodalTextbox(
                placeholder="üí¨ H·ªèi v·ªÅ s·∫£n ph·∫©m ho·∫∑c üì∑ upload ·∫£nh tem nh√£n...",
                file_types=["image"],
                show_label=False,
                submit_btn="G·ª≠i",
                stop_btn="D·ª´ng"
            )
        with gr.Column(scale=1):
            clear = gr.Button("üóëÔ∏è X√≥a l·ªãch s·ª≠", variant="secondary")
    
    # Examples section with better styling
    gr.Markdown("### üí° V√≠ d·ª• c√¢u h·ªèi:")
    
    with gr.Row():
        with gr.Column():
            gr.Examples(
                examples=[
                    {"text": "TV gi√° cao nh·∫•t", "files": []},
                    {"text": "T·ªß l·∫°nh r·∫ª nh·∫•t", "files": []},
                    {"text": "So s√°nh TV Samsung v√† LG", "files": []},
                ],
                inputs=msg,
                label="üéØ Intent Detection"
            )
        
        with gr.Column():
            gr.Examples(
                examples=[
                    {"text": "M√°y l·ªçc n∆∞·ªõc H√≤a Ph√°t", "files": []},
                    {"text": "B√¨nh t·∫Øm Rossi 15 l√≠t", "files": []},
                    {"text": "c√≥ nh·ªØng lo·∫°i tivi n√†o", "files": []},
                ],
                inputs=msg,
                label="üîç Smart Search"
            )
    
    # Footer
    gr.Markdown(
        """
        ---
        <footer>
        <p>‚ö° Powered by <b>Qwen2-VL-7B</b> ‚Ä¢ <b>vLLM</b> ‚Ä¢ <b>SQLite</b> ‚Ä¢ <b>Gradio</b></p>
        <p style="font-size: 0.85em; color: #aaa;">Built with ‚ù§Ô∏è for VIVOHOME Electronics</p>
        </footer>
        """
    )
    
    # Chat logic - Fixed for Gradio 6.0
    def respond(message, chat_history):
        """Handle chat messages with Gradio 6.0 format"""
        # Get bot response
        bot_response = chat_with_agent(message, chat_history)
        
        # Format message for display
        if isinstance(message, dict):
            # Multimodal message
            user_msg = message.get("text", "")
            if message.get("files"):
                user_msg += f" [üì∑ Image uploaded]"
        else:
            user_msg = str(message)
        
        # Append to history in correct format
        chat_history.append({"role": "user", "content": user_msg})
        chat_history.append({"role": "assistant", "content": bot_response})
        
        return "", chat_history
    
    msg.submit(respond, [msg, chatbot], [msg, chatbot])
    clear.click(lambda: [], None, chatbot, queue=False)

if __name__ == "__main__":
    print("=" * 50)
    print("üöÄ VIVOHOME AI Agent - Premium UI")
    print("=" * 50)
    demo.launch(share=True)