import os
import subprocess
import sys
import re
import requests
import pandas as pd

# 1. T·ª± ƒë·ªông c√†i th∆∞ vi·ªán (gi·ªØ nguy√™n t·ª´ b·∫£n c≈©)
def install_if_missing(package):
    try:
        __import__(package)
    except ImportError:
        subprocess.check_call([sys.executable, "-m", "pip", "install", package])

install_if_missing("requests")
install_if_missing("pandas")

# --- BI·∫æN TO√ÄN C·ª§C ƒê·ªÇ L∆ØU L·ªäCH S·ª¨ ---
# C·∫•u tr√∫c: [{"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}]
conversation_history = []

# 2. T√¨m s·∫£n ph·∫©m li√™n quan (Gi·ªØ nguy√™n logic l·ªçc t·ª´ kh√≥a c·ªßa Tuy·ªÅn)
def search_relevant_products(user_question, max_results=5):
    try:
        df = pd.read_csv("product.csv", encoding='utf-8-sig')
        df.columns = df.columns.str.strip()
        
        question_lower = user_question.lower()
        keywords = question_lower.split()
        
        def match_score(row):
            searchable = " ".join([str(row.get('T√™n s·∫£n ph·∫©m', '')), str(row.get('Model', '')), str(row.get('Th√¥ng s·ªë ch√≠nh', ''))]).lower()
            return sum(1 for kw in keywords if kw in searchable)
        
        df['score'] = df.apply(match_score, axis=1)
        df = df.sort_values('score', ascending=False).head(max_results)
        
        knowledge = ""
        for _, row in df.iterrows():
            knowledge += f"- {row['T√™n s·∫£n ph·∫©m']} ({row.get('Model', '')}): {row['Gi√° (VND)']} VND\n"
        return knowledge
    except:
        return "Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu."

# 3. L√†m s·∫°ch ph·∫£n h·ªìi (X√≥a ph·∫ßn <think>)
def clean_response(response):
    cleaned = re.sub(r'<think>.*?</think>', '', response, flags=re.DOTALL)
    return cleaned.strip()

# 4. H√†m g·ªçi AI c√≥ t√≠ch h·ª£p B·ªò NH·ªö
def ask_vivohome(user_question):
    global conversation_history
    
    # L·∫•y ki·∫øn th·ª©c m·ªõi nh·∫•t d·ª±a tr√™n c√¢u h·ªèi
    knowledge_base = search_relevant_products(user_question)
    
    # T·∫°o System Prompt ƒë·ªÉ ƒë·ªãnh h∆∞·ªõng AI
    system_prompt = f"B·∫°n l√† nh√¢n vi√™n VIVOHOME. D·ªØ li·ªáu s·∫£n ph·∫©m:\n{knowledge_base}\nTr·∫£ l·ªùi ng·∫Øn g·ªçn."

    # Th√™m c√¢u h·ªèi hi·ªán t·∫°i v√†o l·ªãch s·ª≠
    conversation_history.append({"role": "user", "content": user_question})

    # Ch·ªâ gi·ªØ l·∫°i 6 tin nh·∫Øn g·∫ßn nh·∫•t (3 c·∫∑p h·ªèi-ƒë√°p) ƒë·ªÉ kh√¥ng b·ªã l·ªói tr√†n Token (1024 limit)
    recent_history = conversation_history[-6:]

    payload = {
        "model": "casperhansen/deepseek-r1-distill-llama-8b-awq",
        "messages": [{"role": "system", "content": system_prompt}] + recent_history,
        "temperature": 0.1,
        "max_tokens": 512
    }
    
    url = "http://127.0.0.1:8000/v1/chat/completions"
    
    try:
        r = requests.post(url, json=payload, timeout=60)
        result = r.json()
        
        if 'choices' in result:
            ai_answer = result['choices'][0]['message']['content']
            ai_answer_cleaned = clean_response(ai_answer)
            
            # L∆ØU C√ÇU TR·∫¢ L·ªúI C·ª¶A AI V√ÄO B·ªò NH·ªö
            conversation_history.append({"role": "assistant", "content": ai_answer_cleaned})
            
            return ai_answer_cleaned
        else:
            return "‚ùå L·ªói: Server kh√¥ng tr·∫£ v·ªÅ n·ªôi dung."
    except Exception as e:
        return f"‚ùå L·ªói k·∫øt n·ªëi: {e}"

# 5. V√≤ng l·∫∑p Chat th·ª±c t·∫ø
if __name__ == "__main__":
    print("\n" + "="*50)
    print("ü§ñ AI VIVOHOME ƒê√É C√ì B·ªò NH·ªö - G√ï 'exit' ƒê·ªÇ THO√ÅT")
    print("="*50)
    
    while True:
        user_input = input("\nüë§ B·∫°n: ")
        if user_input.lower() in ['exit', 'quit', 'tho√°t']:
            break
            
        answer = ask_vivohome(user_input)
        print(f"üí¨ AI: {answer}")